# Jeju RL Training Configuration
# Supports: CUDA GPU, Apple Silicon (MLX), CPU

# ==============================================================================
# REQUIRED FOR ALL TRAINING
# ==============================================================================

# Database connection for trajectory data
DATABASE_URL=postgresql://user:password@localhost:5432/babylon

# OpenAI API key for RLAIF judge (GPT-4o-mini)
OPENAI_API_KEY=sk-...

# ==============================================================================
# ATROPOS TRAINING
# ==============================================================================

# Atropos API server URL
ATROPOS_API_URL=http://localhost:8000

# vLLM inference server port
VLLM_PORT=9001

# ==============================================================================
# BACKEND SELECTION
# ==============================================================================
# If none set, auto-detects: CUDA > MLX > CPU
# Set ONE of these to true to force a specific backend:

# USE_MLX_BACKEND=true      # Apple Silicon Mac (fastest on Mac)
# USE_LOCAL_BACKEND=true    # CUDA GPU (auto-falls back to MLX/CPU if no CUDA)
# USE_CPU_BACKEND=true      # CPU only (SLOW - not recommended)

# ==============================================================================
# MODEL SELECTION
# ==============================================================================
# Leave blank to auto-select based on backend:
# - Default: Qwen/Qwen2.5-3B-Instruct
# - CUDA: Qwen/Qwen2.5-3B-Instruct
# - MLX: mlx-community/Qwen2.5-3B-Instruct-4bit
# - CPU: Qwen/Qwen2.5-1.5B-Instruct

# BASE_MODEL=Qwen/Qwen2.5-3B-Instruct
# BASE_MODEL=mlx-community/Qwen2.5-3B-Instruct-4bit
# BASE_MODEL=mlx-community/Qwen2.5-7B-Instruct-4bit

BASE_MODEL=

# ==============================================================================
# TRAINING CONFIGURATION
# ==============================================================================

# Data selection
MIN_AGENTS_PER_WINDOW=1
# WINDOW_ID=              # Specific window to train (optional)
# MAX_EXAMPLES=2000       # Limit trajectories
# MAX_STEPS_PER_TRAJECTORY=20

# Training hyperparameters
# LEARNING_RATE=1e-5      # Default
# MAX_SEQ_LENGTH=4096     # Context length
# GROUP_SIZE=4            # GRPO group size
# TRAINING_STEPS=100      # Number of steps

# ==============================================================================
# JUDGE MODEL (RLAIF Scoring)
# ==============================================================================

JUDGE_MODEL=gpt-4o-mini
# JUDGE_MODEL=gpt-4o    # Higher quality, higher cost
# JUDGE_TEMPERATURE=0.3
